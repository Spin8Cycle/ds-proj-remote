{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Sequences Using RNNs (Recurrent Neural Networks) and CNNs:\n",
    "\n",
    "* Recurrent Neural Networks :\n",
    "    * A class of nets that can predict the future (..up to a point)\n",
    "    * RNNs can analyze time series data. Once an RNN learns past patterns in the data, it is able to use its knowledge to forecast the future, assuming of course that past patterns still hold in the future.\n",
    "    * RNNs can work on sequences of arbitrary lengths, rather than on fixed-sized inputs.\n",
    "        * They can take sentences, documents, or audio samples as inputs, making them extremely useful for natural language processing applications such as automatic translation or speech-to-text.'\n",
    "    \n",
    "* Two main difficulties that RNNs face:\n",
    "    * Unstable gradients, w/c can be alleviated using various techniques, including recurrent dropout and recurrent layer normalization.\n",
    "    * A very limited short-term memory, w/c can be extended using LSTM and GRU cells.\n",
    "\n",
    "* RNNs are not the only types of neural networks capable of handling sequential data. For small sequences, a regular dense network can do the trick, and for very long sequences, such as audio samples or text, convolutional neural networks can actually work quite well too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Recurrent Nuerons and Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
