{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Example Applications:\n",
    "\n",
    "* Analyzing images of products on a production line to automatically classify them:\n",
    "    * Image classification, typically performed using convolutional neural networks (CNNs) or sometimes transformers.\n",
    "\n",
    "* Detecting tumors in brain scans:\n",
    "    * This is semantic image segmentation, where each pixel in the image is classified (to determine the exact location and shape of tumors), typically using CNNs or transformers.\n",
    "\n",
    "* Automatically classifying news articles:\n",
    "    * NLP --> text classification, w/c can be tackled using recurrent neutral networks (RNNs) and CNNs, but transformers work even better.\n",
    "\n",
    "* Automatically flagging offensive comments on discussion forums:\n",
    "    * This is also text classification, using the same NLP tools.\n",
    "\n",
    "* Summarizing long documents automatically:\n",
    "    * This is a branch of NLP called text summarization, again using the same tools.\n",
    "\n",
    "* Creating a chatbot or a personal assistant:\n",
    "    * This involves many NLP components, including natural language understanding (NLU) and question-answering modules.\n",
    "\n",
    "* Forecasting your company’s revenue next year, based on many performance metrics:\n",
    "    * This is a regression task (i.e., predicting values) that may be tackled using any regression model, such as a linear regression or polynomial regression model, a regression support vector machine, a regression random forest, or an\n",
    "artificial neural network.\n",
    "\n",
    "* Making your app react to voice commands:\n",
    "    * This is speech recognition, which requires processing audio samples: since they are long and complex sequences, they are typically processed using RNNs, CNNs, or transformers.\n",
    "\n",
    "* Detecting credit card fraud:\n",
    "    * This is anomaly detection, which can be tackled using isolation forests, Gaussian mixture models or autoencoders.\n",
    "\n",
    "* Segmenting clients based on their purchases so that you can design a different marketing strategy for each segment:\n",
    "    * This is clustering, which can be achieved using k-means, DBSCAN, and more\n",
    "\n",
    "* Representing a complex, high-dimensional dataset in a clear and insightful diagram:\n",
    "    * This is data visualization, often involving dimensionality reduction techniques\n",
    "\n",
    "* Recommending a product that a client may be interested in, based on past purchases:\n",
    "    * Recommender System\n",
    "    * One approach is to feed past purchases (and other information about the client) to an artificial neural network, and get it to output the most likely next purchase. This neural net would typically be trained on past sequences of purchases across all clients. \n",
    "\n",
    "* Building an intelligent bot for a game\n",
    "    * This is often tackled using reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Types of Machine Learning Systems:\n",
    "\n",
    "* How they are supervised during training?:\n",
    "    * Supervised, Unsupervised, Semi-supervised, Self-supervised , etc.\n",
    "\n",
    "* Whether or not they can learn incrementally on the fly:\n",
    "    * Online versus Batch Learning.\n",
    "\n",
    "* Whether they work by simply comparing new data points to known data points, or instead by detecting patterns in the training data and building a predictive model:\n",
    "    * instance-based versus model based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. Batch Versus Online Learning:\n",
    "\n",
    "* **Batch learning**:\n",
    "    * The system is incapable of learning incrementally, it must be trained using all the available data.\n",
    "    * The system is trained, and then it is launched into production and runs without learning anymore; it just applies what it has learned (**Offline Learning**).\n",
    "    * Unfortunately, a model’s performance tends to decay slowly over time, simply because the world continues to evolve while the model remains unchanged (**model rot or data drift**).\n",
    "        * The solution is to regularly retrain the model on up-to-date data.\n",
    "        * The frequency of training depends on the use case:\n",
    "            * If the model classifies pictures of cats and dogs, its performance will decay very slowly, but if the model deals with fast-evolving systems, for example making predictions on the financial market, then it is likely to decay quite fast.\n",
    "    * For a batch learning system to knwo about new data, you need to train a new version of the system from scratch on the full dataset (old + new) then replace the model w/ a new one.\n",
    "\n",
    "* **Online Learning**:\n",
    "    * The system is trained by incrementally feeding it data instances sequentially, either individually or in small groups called mini-batches.\n",
    "    * Useful for systems that need to adapt to change extremely rapidly.\n",
    "    * It is also a good option if you have limited computing resources; for example, if the model is trained on a mobile device.\n",
    "    * Online learning algorithms can be used to train models on huge datasets that cannot fit in one machine’s main memory (**Out-of-core learning**).\n",
    "        * The algorithm loads part of the data, runs a training step on that data, and repeats the process until it has run on all of the data.\n",
    "        * **Out-of-core learning** is usually done offline (i.e., not on the live system), so online learning can be a confusing name\n",
    "    * One important parameter of online learning systems is how fast they should adapt to changing data (**Learning Rate**).\n",
    "        * If you set a high learning rate, then your system will rapidly adapt to new data, but it will also tend to quickly forget the old data.\n",
    "        * if you set a low learning rate, the system will have more inertia; that is, it will learn more slowly, but it will also be less sensitive to noise in the new data or to sequences of nonrepresentative data points (outliers).\n",
    "        * A big challenge with online learning is that if bad data is fed to the system, the system’s performance will decline, possibly quickly (depending on the data quality and learning rate).\n",
    "        * To reduce this risk, you need to monitor your system closely and promptly switch learning off (and possibly revert to a previously working state) if you detect a drop in performance. You may also want to monitor the input data and react to abnormal data; for example, using an anomaly detection algorithm.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2. Instance-Based Versus Model-Based Learning:\n",
    "* How machine learning systems generalize.\n",
    "\n",
    "* **Instance-based Learning**:\n",
    "    * The system learns the examples by heart, then generalizes to new cases by using a similarity measure to compare them to the learned examples (or a subset of them).\n",
    "\n",
    "* **Model-based Learning**:\n",
    "    * Build a model of these examples and then use that model to make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Main Challenges of Machine Learning:\n",
    "\n",
    "$Bad\\ Data$:\n",
    "### C.1. Insufficient Quantity of Training Data:\n",
    "* It takes a lot of data for most machine learning algorithms to work properly.\n",
    "* Even for very simple problems you typically need thousands of examples, and for complex problems such as image or speech recognition you may need millions of examples (unless you can reuse parts of an existing model).\n",
    "\n",
    "### C.2. Nonrepresentative Training Data:\n",
    "* In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to.\n",
    "* **Sampling Bias**:\n",
    "    * If the sample is too small, you will have sampling noise (i.e., nonrepresentative data as a result of chance), but even very large samples can be nonrepresentative if the sampling method is flawed.\n",
    "\n",
    "### C.3. Poor-Quality Data:\n",
    "* Ff your training data is full of errors, outliers, and noise (e.g., due to poor-quality measurements), it will make it harder for the system to detect the underlying patterns, so your system is less likely to perform well.\n",
    "* It is often well worth the effort to spend time cleaning up your training data.\n",
    "* **When to clean up training data**:\n",
    "    * If some instances are clearly outliers, it may help to simply discard them or try to fix the errors manually.\n",
    "    * If some instances are missing a few features (e.g., 5% of your customers did not specify their age), you must decide whether you want to ignore this attribute altogether, ignore these instances, fill in the missing values (e.g., with the median age), or train one model with the feature and one model without it.\n",
    "\n",
    "### C.4. Irrelevant Features:\n",
    "* *Garbage In, Garbage Out*\n",
    "*  Your system will only be capable of learning if the training data contains enough relevant features and not too many irrelevant ones.\n",
    "* A critical part of the success of a machine learning project is coming up with a good set of features to train on.\n",
    "* **Feature Engineering**:\n",
    "    * Feature selection (selecting the most useful features to train on among existing features)\n",
    "    * Feature extraction (combining existing features to produce a more useful one⁠, dimensionality reduction algorithms can help)\n",
    "    * Creating new features by gathering new data\n",
    "\n",
    "$Bad\\ Algorithms$:\n",
    "### C.5. Overfitting the Training Data:\n",
    "* The model performs well on the training data, but it does not generalize well.\n",
    "* Overfitting happens when the model is too complex relative to the amount and noisiness of the training data.\n",
    "* Possible Solutions:\n",
    "    * Simplify the model by selecting one with fewer parameters (e.g., a linear model rather than a high-degree polynomial model), by reducing the number of attributes in the training data, or by constraining the model (**Regularization**).\n",
    "    * Gather more training data.\n",
    "    * Reduce the noise in the training data (e.g., fix data errors and remove outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
